{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270f1245",
   "metadata": {
    "id": "270f1245"
   },
   "source": [
    "# ICE-4 Text Data: Flattening, Filtering, and Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c5ffe",
   "metadata": {
    "id": "831c5ffe"
   },
   "source": [
    "## (Tutorial) Bag of X\n",
    "Following is a sample of applying bag of n-grams to Yelp academic dataset review, please download it with following link:\n",
    "\n",
    "https://github.com/knowitall/yelp-dataset-challenge/blob/master/data/yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3147f5",
   "metadata": {
    "id": "1b3147f5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d4eda8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81d4eda8",
    "outputId": "e8a83f56-8eed-4e46-d30b-2cfa2499ce76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('C:\\\\Users\\\\PULAPA YESHWANTH\\\\Downloads\\\\yelp_academic_dataset_review.json')\n",
    "js = []\n",
    "for i in range(10000):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "review_df = pd.DataFrame(js)\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778b99ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "778b99ab",
    "outputId": "34aa9aa4-b58a-41a5-9a1b-d958d98d3884"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-22cfce7f-b884-4193-97bf-7b9303208f3c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'funny': 0, 'useful': 5, 'cool': 2}</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'funny': 0, 'useful': 1, 'cool': 0}</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'funny': 0, 'useful': 2, 'cool': 1}</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22cfce7f-b884-4193-97bf-7b9303208f3c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-22cfce7f-b884-4193-97bf-7b9303208f3c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-22cfce7f-b884-4193-97bf-7b9303208f3c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                  votes                 user_id  \\\n",
       "0  {'funny': 0, 'useful': 5, 'cool': 2}  rLtl8ZkDX5vH5nAx9C3q5Q   \n",
       "1  {'funny': 0, 'useful': 0, 'cool': 0}  0a2KyEL0d3Yb1V6aivbIuQ   \n",
       "2  {'funny': 0, 'useful': 1, 'cool': 0}  0hT2KtfLiobPvh6cDC8JQg   \n",
       "3  {'funny': 0, 'useful': 2, 'cool': 1}  uZetl9T0NcROGOyFfughhg   \n",
       "4  {'funny': 0, 'useful': 0, 'cool': 0}  vYmM4KTsC8ZfQBg-j5MWkw   \n",
       "\n",
       "                review_id  stars        date  \\\n",
       "0  fWKvX83p0-ka4JS3dc6E5A      5  2011-01-26   \n",
       "1  IjZ33sJrzXqU-0X6U8NwyA      5  2011-07-27   \n",
       "2  IESLBzqUCLdSzSqm0eCSxQ      4  2012-06-14   \n",
       "3  G-WvGaISbqqaMHlNnByodA      5  2010-05-27   \n",
       "4  1uJFq2r5QfJG_6ExMRCaGw      5  2012-01-05   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "              business_id  \n",
       "0  9yKzy9PApeiPPOUJEtnvkg  \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  \n",
       "4  6ozycU1RpktNG2-1BroVtw  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd8d91",
   "metadata": {
    "id": "83dd8d91"
   },
   "source": [
    "note: in the default settings of CountVectorizer, the token_pattern = '(?u)\\\\b\\\\w\\\\w+\\\\b', which ignores single-character words. Whe employ the token_pattern = '(?u)\\\\b\\\\w+\\\\b' to include the single-character words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41af94dc",
   "metadata": {
    "id": "41af94dc"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_converter = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "x = bow_converter.fit_transform(review_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b766ee",
   "metadata": {
    "id": "f2b766ee"
   },
   "outputs": [],
   "source": [
    "unigram = bow_converter.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50bbec20",
   "metadata": {
    "id": "50bbec20"
   },
   "outputs": [],
   "source": [
    "bigram_converter = CountVectorizer(ngram_range=(2,2), token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "x2 = bigram_converter.fit_transform(review_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b48445d1",
   "metadata": {
    "id": "b48445d1"
   },
   "outputs": [],
   "source": [
    "bigram = bigram_converter.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69ad254",
   "metadata": {
    "id": "a69ad254"
   },
   "outputs": [],
   "source": [
    "trigram_converter = CountVectorizer(ngram_range=(3,3), token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "x3 = trigram_converter.fit_transform(review_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f589e9",
   "metadata": {
    "id": "f6f589e9"
   },
   "outputs": [],
   "source": [
    "trigram = trigram_converter.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074f4366",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "074f4366",
    "outputId": "416ab648-9f70-401f-c7aa-04bdc9b78c07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '00', '000', ..., 'école', 'ém', 'òc'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5115acf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5115acf",
    "outputId": "460ceac0-abe0-4725-f4ac-fb465baf6809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0 0', '0 20', '0 39', ..., 'école lenôtre', 'ém all', 'òc châm'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b01ae08d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b01ae08d",
    "outputId": "a43936a8-e522-43e4-99e8-cf4348984c20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0 0 eye', '0 20 less', '0 39 oz', ..., 'école lenôtre trained',\n",
       "       'ém all they', 'òc châm a'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6055c823",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6055c823",
    "outputId": "a8ae8e5c-91e6-44db-b2b6-5916f57f277d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29222 368943 881620\n"
     ]
    }
   ],
   "source": [
    "print (len(unigram), len(bigram), len(trigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fa90148",
   "metadata": {
    "id": "5fa90148"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c081c74f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "c081c74f",
    "outputId": "7b11ee8c-72a4-448c-8929-3858150a315f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='f7c80724-6a64-4c78-be6b-076fece39e88'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "counts = [len(unigram), len(bigram), len(trigram)]\n",
    "plt.plot(counts, color='cornflowerblue')\n",
    "plt.plot(counts, 'bo')\n",
    "plt.margins(0.1)\n",
    "plt.xticks(range(3), ['unigram', 'bigram', 'trigram'])\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.title('Number of ngrams in the first 10,000 reviews of the Yelp dataset', {'fontsize':16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17766f19",
   "metadata": {
    "id": "17766f19"
   },
   "source": [
    "## Task 1. 1 Applying the unigram, bigram, and trigram tokenization methods to the given text below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26c7b44d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "26c7b44d",
    "outputId": "1fd78c69-f5c8-4f32-f726-8993842e8cf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', 'a', 'absolute', 'absolutely', 'amazing', 'an', 'and',\n",
       "       'anyway', 'arrived', 'back', 'best', 'better', 'birthday', 'blend',\n",
       "       'bloody', 'bread', 'breakfast', 'busy', 'came', 'can', 'complete',\n",
       "       'delicious', 'do', 'earlier', 'eggs', 'ever', 'everything',\n",
       "       'excellent', 'favor', 'fills', 'food', 'for', 'fresh', 'from',\n",
       "       'garden', 'get', 'go', 'griddled', 'grounds', 'had', 'here', 'i',\n",
       "       'ingredients', 'it', 'like', 'looked', 'looks', 'm', 'made',\n",
       "       'mary', 'me', 'meal', 'menu', 'morning', 'my', 'of', 'on', 'only',\n",
       "       'order', 'our', 'outside', 'overlooking', 'perfect', 'phenomenal',\n",
       "       'pieces', 'place', 'pleasure', 'pretty', 'quickly', 'saturday',\n",
       "       'scrambled', 'semi', 'simply', 'sitting', 'skillet', 'so', 'sure',\n",
       "       't', 'tasty', 'the', 'their', 'them', 'they', 'to', 'toast',\n",
       "       'took', 'truffle', 'up', 'use', 've', 'vegetable', 'wait',\n",
       "       'waitress', 'was', 'weather', 'when', 'which', 'while', 'white',\n",
       "       'wife', 'with', 'you', 'yourself'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = \"\"\"My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.\n",
    "Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.\n",
    "I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.\n",
    "It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.\n",
    "It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!\"\"\"\n",
    "\n",
    "# write your code here\n",
    "x = bow_converter.fit_transform([train_text])\n",
    "# Tokens using unigram\n",
    "unigram = bow_converter.get_feature_names_out()\n",
    "# unigram results\n",
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a96kpI7tTuR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "5a96kpI7tTuR",
    "outputId": "ea0915db-b64b-4d8f-adaf-fa8e046f1dbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2 pieces', 'a favor', 'absolute pleasure', 'absolutely made',\n",
       "       'amazing and', 'amazing while', 'an absolute', 'and blend',\n",
       "       'and delicious', 'and get', 'and it', 'and our', 'and simply',\n",
       "       'anyway i', 'arrived quickly', 'best i', 'best toast', 'better do',\n",
       "       'birthday for', 'blend them', 'bloody mary', 'bread with',\n",
       "       'breakfast and', 'busy saturday', 'came with', 'can t',\n",
       "       'complete it', 'delicious it', 'do yourself', 'earlier you',\n",
       "       'eggs vegetable', 'ever had', 'everything on', 'excellent and',\n",
       "       'excellent i', 'excellent the', 'favor and', 'fills up',\n",
       "       'food arrived', 'for breakfast', 'fresh when', 'from their',\n",
       "       'garden and', 'get here', 'get their', 'go back', 'griddled bread',\n",
       "       'grounds an', 'had anyway', 'had i', 'had the', 'here on',\n",
       "       'here the', 'i can', 'i had', 'i m', 'i ve', 'ingredients from',\n",
       "       'it absolutely', 'it came', 'it it', 'it looked', 'it was',\n",
       "       'like the', 'looked like', 'looks excellent', 'm pretty',\n",
       "       'made sitting', 'made the', 'mary it', 'me here', 'meal complete',\n",
       "       'menu looks', 'morning it', 'my birthday', 'my wife', 'of their',\n",
       "       'on my', 'on the', 'only use', 'order it', 'our food',\n",
       "       'our waitress', 'outside overlooking', 'overlooking their',\n",
       "       'perfect which', 'phenomenal and', 'pieces of', 'place fills',\n",
       "       'pleasure our', 'pretty quickly', 'pretty sure', 'quickly on',\n",
       "       'quickly so', 'saturday morning', 'scrambled eggs', 'semi busy',\n",
       "       'simply the', 'sitting outside', 'skillet and', 'so the',\n",
       "       'sure they', 't wait', 'tasty and', 'the best', 'the better',\n",
       "       'the earlier', 'the meal', 'the menu', 'the place', 'the semi',\n",
       "       'the weather', 'the white', 'their bloody', 'their garden',\n",
       "       'their griddled', 'their grounds', 'them fresh', 'they only',\n",
       "       'to go', 'toast i', 'took me', 'truffle scrambled', 'up pretty',\n",
       "       'use ingredients', 've ever', 'vegetable skillet', 'wait to',\n",
       "       'waitress was', 'was amazing', 'was excellent', 'was perfect',\n",
       "       'was phenomenal', 'was tasty', 'was the', 'weather was',\n",
       "       'when you', 'which made', 'while everything', 'white truffle',\n",
       "       'wife took', 'with 2', 'with was', 'you get', 'you order',\n",
       "       'yourself a'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_converter = CountVectorizer(ngram_range=(2,2), token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "x2 = bigram_converter.fit_transform([train_text])\n",
    "bigram = bigram_converter.get_feature_names_out()\n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mO96zLF6vn7s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "mO96zLF6vn7s",
    "outputId": "b5ed59fb-0621-4596-cf5e-49924524e416"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2 pieces of', 'a favor and', 'absolute pleasure our',\n",
       "       'absolutely made the', 'amazing and it',\n",
       "       'amazing while everything', 'an absolute pleasure',\n",
       "       'and blend them', 'and delicious it', 'and get their',\n",
       "       'and it absolutely', 'and it was', 'and our food',\n",
       "       'and simply the', 'anyway i can', 'arrived quickly on',\n",
       "       'best i ve', 'best toast i', 'better do yourself',\n",
       "       'birthday for breakfast', 'blend them fresh', 'bloody mary it',\n",
       "       'bread with was', 'breakfast and it', 'busy saturday morning',\n",
       "       'came with 2', 'can t wait', 'complete it was',\n",
       "       'delicious it came', 'do yourself a', 'earlier you get',\n",
       "       'eggs vegetable skillet', 'ever had anyway', 'ever had i',\n",
       "       'everything on the', 'excellent and our', 'excellent i had',\n",
       "       'excellent the weather', 'favor and get', 'fills up pretty',\n",
       "       'food arrived quickly', 'for breakfast and', 'fresh when you',\n",
       "       'from their garden', 'garden and blend', 'get here the',\n",
       "       'get their bloody', 'griddled bread with', 'grounds an absolute',\n",
       "       'had anyway i', 'had i m', 'had the white', 'here on my',\n",
       "       'here the better', 'i can t', 'i had the', 'i m pretty',\n",
       "       'i ve ever', 'ingredients from their', 'it absolutely made',\n",
       "       'it came with', 'it it was', 'it looked like', 'it was amazing',\n",
       "       'it was excellent', 'it was phenomenal', 'it was tasty',\n",
       "       'it was the', 'like the place', 'looked like the',\n",
       "       'looks excellent i', 'm pretty sure', 'made sitting outside',\n",
       "       'made the meal', 'mary it was', 'me here on', 'meal complete it',\n",
       "       'menu looks excellent', 'morning it looked', 'my birthday for',\n",
       "       'my wife took', 'of their griddled', 'on my birthday',\n",
       "       'on the menu', 'on the semi', 'only use ingredients',\n",
       "       'order it it', 'our food arrived', 'our waitress was',\n",
       "       'outside overlooking their', 'overlooking their grounds',\n",
       "       'perfect which made', 'phenomenal and simply', 'pieces of their',\n",
       "       'place fills up', 'pleasure our waitress', 'pretty quickly so',\n",
       "       'pretty sure they', 'quickly on the', 'quickly so the',\n",
       "       'saturday morning it', 'scrambled eggs vegetable',\n",
       "       'semi busy saturday', 'simply the best',\n",
       "       'sitting outside overlooking', 'skillet and it', 'so the earlier',\n",
       "       'sure they only', 't wait to', 'tasty and delicious', 'the best i',\n",
       "       'the best toast', 'the better do', 'the earlier you',\n",
       "       'the meal complete', 'the menu looks', 'the place fills',\n",
       "       'the semi busy', 'the weather was', 'the white truffle',\n",
       "       'their bloody mary', 'their garden and', 'their griddled bread',\n",
       "       'their grounds an', 'them fresh when', 'they only use',\n",
       "       'to go back', 'toast i ve', 'took me here',\n",
       "       'truffle scrambled eggs', 'up pretty quickly',\n",
       "       'use ingredients from', 've ever had', 'vegetable skillet and',\n",
       "       'wait to go', 'waitress was excellent', 'was amazing and',\n",
       "       'was amazing while', 'was excellent and', 'was excellent the',\n",
       "       'was perfect which', 'was phenomenal and', 'was tasty and',\n",
       "       'was the best', 'weather was perfect', 'when you order',\n",
       "       'which made sitting', 'while everything on',\n",
       "       'white truffle scrambled', 'wife took me', 'with 2 pieces',\n",
       "       'with was amazing', 'you get here', 'you order it',\n",
       "       'yourself a favor'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_converter = CountVectorizer(ngram_range=(3,3), token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "x3 = trigram_converter.fit_transform([train_text])\n",
    "trigram = trigram_converter.get_feature_names_out()\n",
    "trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9bc618",
   "metadata": {
    "id": "7d9bc618"
   },
   "source": [
    "## Task 1.2 Create your own naive tokenization method (whitespace-based), and apply it to the text given in the task 1.1\n",
    "note: 1. do not use the existing togkenization methods given by NLP; 2. split the words by whitespace character, the output is more likely as the unigram; 3. no repeating elements in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c40457a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "2c40457a",
    "outputId": "82f50098-824e-4744-d435-787b0c2c478a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'wife', 'took', 'me', 'here', 'on', 'my', 'birthday', 'for', 'breakfast', 'and', 'it', 'was', 'excellent.', 'The', 'weather', 'perfect', 'which', 'made', 'sitting', 'outside', 'overlooking', 'their', 'grounds', 'an', 'absolute', 'pleasure.', 'Our', 'waitress', 'excellent', 'our', 'food', 'arrived', 'quickly', 'the', 'semi-busy', 'Saturday', 'morning.', 'It', 'looked', 'like', 'place', 'fills', 'up', 'pretty', 'so', 'earlier', 'you', 'get', 'better.', 'Do', 'yourself', 'a', 'favor', 'Bloody', 'Mary.', 'phenomenal', 'simply', 'best', \"I've\", 'ever', 'had.', \"I'm\", 'sure', 'they', 'only', 'use', 'ingredients', 'from', 'garden', 'blend', 'them', 'fresh', 'when', 'order', 'it.', 'amazing.', 'While', 'EVERYTHING', 'menu', 'looks', 'excellent,', 'I', 'had', 'white', 'truffle', 'scrambled', 'eggs', 'vegetable', 'skillet', 'tasty', 'delicious.', 'came', 'with', '2', 'pieces', 'of', 'griddled', 'bread', 'amazing', 'absolutely', 'meal', 'complete.', '\"toast\"', 'Anyway,', \"can't\", 'wait', 'to', 'go', 'back!']\n"
     ]
    }
   ],
   "source": [
    "# tokenization method\n",
    "word_tokens = train_text.split()\n",
    "storing_tokens = []\n",
    "\n",
    "for i in word_tokens:\n",
    "    if i not in storing_tokens:\n",
    "        storing_tokens.append(i)\n",
    "\n",
    "print(storing_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb5c1b",
   "metadata": {
    "id": "e0bb5c1b"
   },
   "source": [
    "## **Question 1**. Given a sentence \"He likes cat\". In unigram representation, it could be \"He\", \"likes\", \"cat\". In bigram representation, it could be \"He likes\", \"likes cat\". In trigram representation, it could be \"He likes cat\". Explain why the storage and computation cost increase with the growth of n in n-gram methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb139d",
   "metadata": {
    "id": "83eb139d"
   },
   "source": [
    "Answer to Q1:\n",
    "Definitely storage and computation cost increases with the growth of n in n-gram methods. There are several reasons for the growth of n in n-gram methods.\n",
    "1. Increases the vocabulary size as the growth of n in n-gram methods.It leads to more storage and computation cost .\n",
    "2. As the n-gram increases more features extracted from the raw text document . If we build the model using these features , it would require more time complexity .\n",
    "3. It can lead to data sparsity as the flow of features increases.\n",
    "4. Dimensionality space also increases with high n-grams.It leads to curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07a909",
   "metadata": {
    "id": "3f07a909"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9bd1f",
   "metadata": {
    "id": "4ee9bd1f"
   },
   "source": [
    "## (Tutorial) Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c0ac9b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "0c0ac9b0",
    "outputId": "62dffab2-2ee1-4f16-830d-97085e704da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'flowers' after stemming: flower\n",
      "'zeroes' after stemming: zero\n",
      "'better' after stemming: better\n",
      "'sixties' after stemming: sixti\n",
      "'goes' after stemming: goe\n",
      "'go' after stemming: go\n"
     ]
    }
   ],
   "source": [
    "# import PorterStemmer class form nltk.stem.porter module\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stem = stemmer.stem('flowers')\n",
    "print(f\"'flowers' after stemming: {stem}\")\n",
    "\n",
    "stem = stemmer.stem('zeroes')\n",
    "print(f\"'zeroes' after stemming: {stem}\")\n",
    "\n",
    "stem = stemmer.stem('better')\n",
    "print(f\"'better' after stemming: {stem}\")\n",
    "\n",
    "stem = stemmer.stem('sixties')\n",
    "print(f\"'sixties' after stemming: {stem}\")\n",
    "\n",
    "stem = stemmer.stem('goes')\n",
    "print(f\"'goes' after stemming: {stem}\")\n",
    "\n",
    "stem = stemmer.stem('go')\n",
    "print(f\"'go' after stemming: {stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0brE1HjYyK6G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "0brE1HjYyK6G",
    "outputId": "03b8f768-1c73-451d-dd6b-5775fa6fce9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c4d270f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "0c4d270f",
    "outputId": "e8e1504c-a278-4f99-dec3-1832129787f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'flowers' after lemmatization: flower\n",
      "'zeros' after lemmatization: zero\n",
      "'better' after lemmatization: better\n",
      "'sixties' after lemmatization: sixty\n",
      "'goes' after lemmatization: go\n",
      "'go' after lemmatization: go\n",
      "\n",
      "\n",
      "\n",
      "'better' (as an adjective) after lemmatization: good\n"
     ]
    }
   ],
   "source": [
    "# import lemmatizer class from nltk.stem module\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemma = lemmatizer.lemmatize('flowers')\n",
    "print(f\"'flowers' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('zeros')\n",
    "print(f\"'zeros' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('better')\n",
    "print(f\"'better' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('sixties')\n",
    "print(f\"'sixties' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('goes')\n",
    "print(f\"'goes' after lemmatization: {lemma}\")\n",
    "\n",
    "lemma = lemmatizer.lemmatize('go')\n",
    "print(f\"'go' after lemmatization: {lemma}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "lemma = lemmatizer.lemmatize('better', pos='a')   # 'a' denoted ADJECTIVE part-of-speech\n",
    "print(f\"'better' (as an adjective) after lemmatization: {lemma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f2000",
   "metadata": {
    "id": "dc7f2000"
   },
   "source": [
    "## Task 2. Text filtering for cleaner feature\n",
    "1. clean the text used in the task 1; 2. remove all punctuations; 3. convert all characters to their lowercase; 4. remove all words in \"stopwords\"; 5. remove all relatively meaningless words like \" 've \", \" 's \", etc. 6. after finishing the above operations, apply stemming and lemmatization to the cleaned text respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Iy1CSBv6KYJx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "Iy1CSBv6KYJx",
    "outputId": "3eb43b3d-3acf-4a04-f55c-fff72b81b438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure\n",
      "Our waitress was excellent and our food arrived quickly on the semibusy Saturday morning  It looked like the place fills up pretty quickly so the earlier you get here the better\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary  It was phenomenal and simply the best Ive ever had\n",
      "Im pretty sure they only use ingredients from their garden and blend them fresh when you order it  It was amazing\n",
      "\n",
      "While EVERYTHING on the menu looks excellent I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious\n",
      "It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete\n",
      "It was the best toast Ive ever had\n",
      "\n",
      "Anyway I cant wait to go back\n"
     ]
    }
   ],
   "source": [
    "# Removing all punctuations\n",
    "import string\n",
    "translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "train_text = train_text.translate(translator)\n",
    "\n",
    "print(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "AON0u7DvKX8X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "AON0u7DvKX8X",
    "outputId": "5c4b04e2-4a91-4869-c445-b46cb549524d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my wife took me here on my birthday for breakfast and it was excellent  the weather was perfect which made sitting outside overlooking their grounds an absolute pleasure\n",
      "our waitress was excellent and our food arrived quickly on the semibusy saturday morning  it looked like the place fills up pretty quickly so the earlier you get here the better\n",
      "\n",
      "do yourself a favor and get their bloody mary  it was phenomenal and simply the best ive ever had\n",
      "im pretty sure they only use ingredients from their garden and blend them fresh when you order it  it was amazing\n",
      "\n",
      "while everything on the menu looks excellent i had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious\n",
      "it came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete\n",
      "it was the best toast ive ever had\n",
      "\n",
      "anyway i cant wait to go back\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "train_text = train_text.lower()\n",
    "\n",
    "print(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "PURXdMQnKX42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "PURXdMQnKX42",
    "outputId": "4c48b1e8-2d7c-4264-def2-16a79ba7a192"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wife took birthday breakfast excellent weather perfect made sitting outside overlooking grounds absolute pleasure waitress excellent food arrived quickly semibusy saturday morning looked like place fills pretty quickly earlier get better favor get bloody mary phenomenal simply best ive ever im pretty sure use ingredients garden blend fresh order amazing everything menu looks excellent white truffle scrambled eggs vegetable skillet tasty delicious came 2 pieces griddled bread amazing absolutely made meal complete best toast ive ever anyway cant wait go back\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = nltk.word_tokenize(train_text)\n",
    "words = [word for word in words if word not in stop_words]\n",
    "cleaned_text = ' '.join(words)\n",
    "\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "KrTRKZExKX0z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "KrTRKZExKX0z",
    "outputId": "8f8161f3-920d-4b00-b42a-a4b8c60ac390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wife took birthday breakfast excellent weather perfect made sitting outside overlooking grounds absolute pleasure waitress excellent food arrived quickly semibusy saturday morning looked like place fills pretty quickly earlier get better favor get bloody mary phenomenal simply best ive ever im pretty sure use ingredients garden blend fresh order amazing everything menu looks excellent white truffle scrambled eggs vegetable skillet tasty delicious came 2 pieces griddled bread amazing absolutely made meal complete best toast ive ever anyway cant wait go back\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Defining meaningless words\n",
    "meaningless_words = [\"'ve\", \"'s\"]\n",
    "\n",
    "# discarding words using regular expression\n",
    "final_text = re.sub(r\"\\b(?:%s)\\b\" % \"|\".join(meaningless_words), \"\", cleaned_text)\n",
    "\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "H7m-mgdoedE_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "H7m-mgdoedE_",
    "outputId": "db4722c2-3a7c-4c5f-9fb4-39c086c0d7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens:\n",
      "['wife', 'took', 'birthday', 'breakfast', 'excel', 'weather', 'perfect', 'made', 'sit', 'outsid', 'overlook', 'ground', 'absolut', 'pleasur', 'waitress', 'excel', 'food', 'arriv', 'quickli', 'semibusi', 'saturday', 'morn', 'look', 'like', 'place', 'fill', 'pretti', 'quickli', 'earlier', 'get', 'better', 'favor', 'get', 'bloodi', 'mari', 'phenomen', 'simpli', 'best', 'ive', 'ever', 'im', 'pretti', 'sure', 'use', 'ingredi', 'garden', 'blend', 'fresh', 'order', 'amaz', 'everyth', 'menu', 'look', 'excel', 'white', 'truffl', 'scrambl', 'egg', 'veget', 'skillet', 'tasti', 'delici', 'came', '2', 'piec', 'griddl', 'bread', 'amaz', 'absolut', 'made', 'meal', 'complet', 'best', 'toast', 'ive', 'ever', 'anyway', 'cant', 'wait', 'go', 'back']\n",
      "\n",
      "Lemmatized Tokens:\n",
      "['wife', 'took', 'birthday', 'breakfast', 'excellent', 'weather', 'perfect', 'made', 'sitting', 'outside', 'overlooking', 'ground', 'absolute', 'pleasure', 'waitress', 'excellent', 'food', 'arrived', 'quickly', 'semibusy', 'saturday', 'morning', 'looked', 'like', 'place', 'fill', 'pretty', 'quickly', 'earlier', 'get', 'better', 'favor', 'get', 'bloody', 'mary', 'phenomenal', 'simply', 'best', 'ive', 'ever', 'im', 'pretty', 'sure', 'use', 'ingredient', 'garden', 'blend', 'fresh', 'order', 'amazing', 'everything', 'menu', 'look', 'excellent', 'white', 'truffle', 'scrambled', 'egg', 'vegetable', 'skillet', 'tasty', 'delicious', 'came', '2', 'piece', 'griddled', 'bread', 'amazing', 'absolutely', 'made', 'meal', 'complete', 'best', 'toast', 'ive', 'ever', 'anyway', 'cant', 'wait', 'go', 'back']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(final_text)\n",
    "# Initialize the stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply stemming\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Apply lemmatization\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "print(\"Stemmed Tokens:\")\n",
    "print(stemmed_tokens)\n",
    "print(\"\\nLemmatized Tokens:\")\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79309e44",
   "metadata": {
    "id": "79309e44"
   },
   "source": [
    "## **Question 2.** Based on the examples and the output of your code, which one has the better performance, Stemming or Lemmatization? Try to analyze it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ee6dd",
   "metadata": {
    "id": "104ee6dd"
   },
   "source": [
    "**Answer to Q2**:\n",
    "As we have seen in the output of stemming . Some of the results are meaning less . outside became outsid after applying stemming which is not in the dictionary. But we can see meaningful word in the lemmatized tokens.The stemmed tokens retain the original form of the words, but they might be truncated or modified to their root form using stemming algorithms.\n",
    "Some examples of stemmed tokens in this text include: \"excel\" (from \"excellent\"), \"outsid\" (from \"outside\"), \"arriv\" (from \"arrived\"), and \"amaz\" (from \"amazing\").\n",
    "The lemmatized tokens are transformed to their base or dictionary form, providing a more standardized representation of the words.\n",
    "Some examples of lemmatized tokens in this text include: \"excellent\" (instead of \"excel\"), \"outside\" (instead of \"outsid\"), \"arrived\" (instead of \"arriv\"), and \"amazing\" (instead of \"amaz\").\n",
    "\n",
    "Based on my analysis lemmatization performed best compared to stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d86bb",
   "metadata": {
    "id": "5b1d86bb"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eaf458",
   "metadata": {
    "id": "67eaf458"
   },
   "source": [
    "## (Tutorial) PoS tagging and chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32f14c",
   "metadata": {
    "id": "fb32f14c"
   },
   "source": [
    "**note:** you need to install spacy and textblob modules first for the following codes\n",
    "If you have problem to install spacy module, try to follow the instruction in the following link:\n",
    "https://stackoverflow.com/questions/66149878/e053-could-not-read-config-cfg-resumeparser\n",
    "If you have problem to use textblob module, try to install nltk libraries as shown in the following link:\n",
    "http://www.nltk.org/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bcfb6e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6bcfb6e6",
    "outputId": "fb6d0d40-9162-4b16-e7b2-9a091c11f899"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the first 10 reviews\n",
    "f = open('yelp_academic_dataset_review.json')\n",
    "js = []\n",
    "for i in range(10):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "review_df = pd.DataFrame(js)\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "589eb7b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "589eb7b2",
    "outputId": "056fad9b-84ea-462e-bc50-fa2b50fc3d31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lang': 'en',\n",
       " 'name': 'core_web_sm',\n",
       " 'version': '3.5.0',\n",
       " 'description': 'English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.',\n",
       " 'author': 'Explosion',\n",
       " 'email': 'contact@explosion.ai',\n",
       " 'url': 'https://explosion.ai',\n",
       " 'license': 'MIT',\n",
       " 'spacy_version': '>=3.5.0,<3.6.0',\n",
       " 'spacy_git_version': '9e0322de1',\n",
       " 'vectors': {'width': 0, 'vectors': 0, 'keys': 0, 'name': None},\n",
       " 'labels': {'tok2vec': [],\n",
       "  'tagger': ['$',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   '-LRB-',\n",
       "   '-RRB-',\n",
       "   '.',\n",
       "   ':',\n",
       "   'ADD',\n",
       "   'AFX',\n",
       "   'CC',\n",
       "   'CD',\n",
       "   'DT',\n",
       "   'EX',\n",
       "   'FW',\n",
       "   'HYPH',\n",
       "   'IN',\n",
       "   'JJ',\n",
       "   'JJR',\n",
       "   'JJS',\n",
       "   'LS',\n",
       "   'MD',\n",
       "   'NFP',\n",
       "   'NN',\n",
       "   'NNP',\n",
       "   'NNPS',\n",
       "   'NNS',\n",
       "   'PDT',\n",
       "   'POS',\n",
       "   'PRP',\n",
       "   'PRP$',\n",
       "   'RB',\n",
       "   'RBR',\n",
       "   'RBS',\n",
       "   'RP',\n",
       "   'SYM',\n",
       "   'TO',\n",
       "   'UH',\n",
       "   'VB',\n",
       "   'VBD',\n",
       "   'VBG',\n",
       "   'VBN',\n",
       "   'VBP',\n",
       "   'VBZ',\n",
       "   'WDT',\n",
       "   'WP',\n",
       "   'WP$',\n",
       "   'WRB',\n",
       "   'XX',\n",
       "   '_SP',\n",
       "   '``'],\n",
       "  'parser': ['ROOT',\n",
       "   'acl',\n",
       "   'acomp',\n",
       "   'advcl',\n",
       "   'advmod',\n",
       "   'agent',\n",
       "   'amod',\n",
       "   'appos',\n",
       "   'attr',\n",
       "   'aux',\n",
       "   'auxpass',\n",
       "   'case',\n",
       "   'cc',\n",
       "   'ccomp',\n",
       "   'compound',\n",
       "   'conj',\n",
       "   'csubj',\n",
       "   'csubjpass',\n",
       "   'dative',\n",
       "   'dep',\n",
       "   'det',\n",
       "   'dobj',\n",
       "   'expl',\n",
       "   'intj',\n",
       "   'mark',\n",
       "   'meta',\n",
       "   'neg',\n",
       "   'nmod',\n",
       "   'npadvmod',\n",
       "   'nsubj',\n",
       "   'nsubjpass',\n",
       "   'nummod',\n",
       "   'oprd',\n",
       "   'parataxis',\n",
       "   'pcomp',\n",
       "   'pobj',\n",
       "   'poss',\n",
       "   'preconj',\n",
       "   'predet',\n",
       "   'prep',\n",
       "   'prt',\n",
       "   'punct',\n",
       "   'quantmod',\n",
       "   'relcl',\n",
       "   'xcomp'],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': ['CARDINAL',\n",
       "   'DATE',\n",
       "   'EVENT',\n",
       "   'FAC',\n",
       "   'GPE',\n",
       "   'LANGUAGE',\n",
       "   'LAW',\n",
       "   'LOC',\n",
       "   'MONEY',\n",
       "   'NORP',\n",
       "   'ORDINAL',\n",
       "   'ORG',\n",
       "   'PERCENT',\n",
       "   'PERSON',\n",
       "   'PRODUCT',\n",
       "   'QUANTITY',\n",
       "   'TIME',\n",
       "   'WORK_OF_ART']},\n",
       " 'pipeline': ['tok2vec',\n",
       "  'tagger',\n",
       "  'parser',\n",
       "  'attribute_ruler',\n",
       "  'lemmatizer',\n",
       "  'ner'],\n",
       " 'components': ['tok2vec',\n",
       "  'tagger',\n",
       "  'parser',\n",
       "  'senter',\n",
       "  'attribute_ruler',\n",
       "  'lemmatizer',\n",
       "  'ner'],\n",
       " 'disabled': ['senter'],\n",
       " 'sources': [{'name': 'OntoNotes 5',\n",
       "   'url': 'https://catalog.ldc.upenn.edu/LDC2013T19',\n",
       "   'license': 'commercial (licensed by Explosion)',\n",
       "   'author': 'Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, Ann Houston'},\n",
       "  {'name': 'ClearNLP Constituent-to-Dependency Conversion',\n",
       "   'url': 'https://github.com/clir/clearnlp-guidelines/blob/master/md/components/dependency_conversion.md',\n",
       "   'license': 'Citation provided for reference, no code packaged with model',\n",
       "   'author': 'Emory University'},\n",
       "  {'name': 'WordNet 3.0',\n",
       "   'url': 'https://wordnet.princeton.edu/',\n",
       "   'author': 'Princeton University',\n",
       "   'license': 'WordNet 3.0 License'}],\n",
       " 'requirements': [],\n",
       " 'source': '/usr/local/lib/python3.10/dist-packages/en_core_web_sm',\n",
       " 'download_url': 'https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunking in spaCy\n",
    "import spacy\n",
    "spacy.info('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e21fc5d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "e21fc5d1",
    "outputId": "208f9228-077a-4520-ca95-47fa2c2dd4d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc_df = review_df['text'].apply(nlp)\n",
    "type(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39951f32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "39951f32",
    "outputId": "1cea9507-de7c-4f4b-fa38-c6b925b4baeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61da0362",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "61da0362",
    "outputId": "0224faca-edd0-4fad-f6b8-de615930387c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Manager Scott Petello is a good egg!!! Not to go into detail, but let me assure you if you have any issues (albeit rare) speak with Scott and treat the guy with some respect as you state your case and I'd be surprised if you don't walk out totally satisfied as I just did. Like I always say..... \"Mistakes are inevitable, it's how we recover from them that is important\"!!!\n",
       "\n",
       "Thanks to Scott and his awesome staff. You've got a customer for life!! .......... :^)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67b329e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "67b329e8",
    "outputId": "b9634cbd-5f29-40fe-84f8-89b4011b9a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General PROPN NNP\n",
      "Manager PROPN NNP\n",
      "Scott PROPN NNP\n",
      "Petello PROPN NNP\n",
      "is AUX VBZ\n",
      "a DET DT\n",
      "good ADJ JJ\n",
      "egg NOUN NN\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "Not PART RB\n",
      "to PART TO\n",
      "go VERB VB\n",
      "into ADP IN\n",
      "detail NOUN NN\n",
      ", PUNCT ,\n",
      "but CCONJ CC\n",
      "let VERB VB\n",
      "me PRON PRP\n",
      "assure VERB VB\n",
      "you PRON PRP\n",
      "if SCONJ IN\n",
      "you PRON PRP\n",
      "have VERB VBP\n",
      "any DET DT\n",
      "issues NOUN NNS\n",
      "( PUNCT -LRB-\n",
      "albeit ADV RB\n",
      "rare ADJ JJ\n",
      ") PUNCT -RRB-\n",
      "speak VERB VBP\n",
      "with ADP IN\n",
      "Scott PROPN NNP\n",
      "and CCONJ CC\n",
      "treat VERB VB\n",
      "the DET DT\n",
      "guy NOUN NN\n",
      "with ADP IN\n",
      "some DET DT\n",
      "respect NOUN NN\n",
      "as SCONJ IN\n",
      "you PRON PRP\n",
      "state VERB VBP\n",
      "your PRON PRP$\n",
      "case NOUN NN\n",
      "and CCONJ CC\n",
      "I PRON PRP\n",
      "'d AUX MD\n",
      "be AUX VB\n",
      "surprised ADJ JJ\n",
      "if SCONJ IN\n",
      "you PRON PRP\n",
      "do AUX VBP\n",
      "n't PART RB\n",
      "walk VERB VB\n",
      "out ADP RP\n",
      "totally ADV RB\n",
      "satisfied ADJ JJ\n",
      "as SCONJ IN\n",
      "I PRON PRP\n",
      "just ADV RB\n",
      "did VERB VBD\n",
      ". PUNCT .\n",
      "Like INTJ UH\n",
      "I PRON PRP\n",
      "always ADV RB\n",
      "say VERB VBP\n",
      "..... PUNCT :\n",
      "\" PUNCT ``\n",
      "Mistakes NOUN NNS\n",
      "are AUX VBP\n",
      "inevitable ADJ JJ\n",
      ", PUNCT ,\n",
      "it PRON PRP\n",
      "'s AUX VBZ\n",
      "how SCONJ WRB\n",
      "we PRON PRP\n",
      "recover VERB VBP\n",
      "from ADP IN\n",
      "them PRON PRP\n",
      "that PRON WDT\n",
      "is AUX VBZ\n",
      "important ADJ JJ\n",
      "\" PUNCT ''\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "Thanks NOUN NNS\n",
      "to ADP IN\n",
      "Scott PROPN NNP\n",
      "and CCONJ CC\n",
      "his PRON PRP$\n",
      "awesome ADJ JJ\n",
      "staff NOUN NN\n",
      ". PUNCT .\n",
      "You PRON PRP\n",
      "'ve AUX VBP\n",
      "got VERB VBN\n",
      "a DET DT\n",
      "customer NOUN NN\n",
      "for ADP IN\n",
      "life NOUN NN\n",
      "! PUNCT .\n",
      "! PUNCT .\n",
      ".......... PUNCT NFP\n",
      ": PUNCT NFP\n",
      "^ X ADD\n",
      ") PUNCT -RRB-\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_df[4]:\n",
    "    print(doc.text, doc.pos_, doc.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aba17d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "4aba17d5",
    "outputId": "632a4e2f-6f6c-4ca0-f295-6dd58051b7bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[General Manager Scott Petello, a good egg, detail, me, you, you, any issues, Scott, the guy, some respect, you, your case, I, you, I, I, Mistakes, it, we, them, that, Thanks, Scott, his awesome staff, You, a customer, life]\n"
     ]
    }
   ],
   "source": [
    "# spaCy also does some basic noun chunking\n",
    "print([chunk for chunk in doc_df[4].noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "413d718f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "413d718f",
    "outputId": "742c9e69-1da7-4888-863c-4e0f9ebd0da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunking in textblob\n",
    "\n",
    "from textblob import TextBlob\n",
    "blob_df = review_df['text'].apply(TextBlob)\n",
    "type(blob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dd9f4fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9dd9f4fc",
    "outputId": "50f85de8-f261-44f1-9412-f8caa5f14f18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blob_df[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "DpKFIE2wywuZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "DpKFIE2wywuZ",
    "outputId": "6ccde08c-c032-4a3b-c05d-f7b30e2aaecc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1900e5b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1900e5b6",
    "outputId": "451e7dc4-add9-4032-cc88-d455b0e1cda3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('General', 'NNP'),\n",
       " ('Manager', 'NNP'),\n",
       " ('Scott', 'NNP'),\n",
       " ('Petello', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('egg', 'NN'),\n",
       " ('Not', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('into', 'IN'),\n",
       " ('detail', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('let', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('assure', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('any', 'DT'),\n",
       " ('issues', 'NNS'),\n",
       " ('albeit', 'IN'),\n",
       " ('rare', 'NN'),\n",
       " ('speak', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('Scott', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('treat', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('guy', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('respect', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('state', 'NN'),\n",
       " ('your', 'PRP$'),\n",
       " ('case', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " (\"'d\", 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('surprised', 'VBN'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('walk', 'VB'),\n",
       " ('out', 'RP'),\n",
       " ('totally', 'RB'),\n",
       " ('satisfied', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('did', 'VBD'),\n",
       " ('Like', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('always', 'RB'),\n",
       " ('say', 'VBP'),\n",
       " ('.....', 'JJ'),\n",
       " ('Mistakes', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('inevitable', 'JJ'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('how', 'WRB'),\n",
       " ('we', 'PRP'),\n",
       " ('recover', 'VBP'),\n",
       " ('from', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('that', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('important', 'JJ'),\n",
       " ('Thanks', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('Scott', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('his', 'PRP$'),\n",
       " ('awesome', 'JJ'),\n",
       " ('staff', 'NN'),\n",
       " ('You', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('got', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('customer', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('life', 'NN'),\n",
       " ('..........', 'NN'),\n",
       " ('^', 'NN')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df[4].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "InhZ6Dq2y_Lx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "InhZ6Dq2y_Lx",
    "outputId": "e161fc44-5c79-4a29-ad83-48bc39d0df5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e138c24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0e138c24",
    "outputId": "b1aa1624-d472-4c8f-987d-277ff7aaf74d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['general manager', 'scott petello', 'good egg', 'scott', \"n't walk\", 'mistakes', 'thanks', 'scott', 'awesome staff']\n"
     ]
    }
   ],
   "source": [
    "# textblob can do some basic noun chunking\n",
    "print([np for np in blob_df[4].noun_phrases])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5f7f2",
   "metadata": {
    "id": "04c5f7f2"
   },
   "source": [
    "## Task 3. Apply spacy and textblob chunking to the text used in tesk 1 respectively, and output the noun phrase chunking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "Po3uOlzBuxQ8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Po3uOlzBuxQ8",
    "outputId": "e8b2f034-82f9-430d-b9c6-174bac258382"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy chunking for the train_text\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc_df = nlp(train_text)\n",
    "type(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "pAf7WMbSuxMX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pAf7WMbSuxMX",
    "outputId": "4a7181fa-eef1-406f-e0dc-425a08fff99b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my PRON PRP$\n",
      "wife NOUN NN\n",
      "took VERB VBD\n",
      "me PRON PRP\n",
      "here ADV RB\n",
      "on ADP IN\n",
      "my PRON PRP$\n",
      "birthday NOUN NN\n",
      "for ADP IN\n",
      "breakfast NOUN NN\n",
      "and CCONJ CC\n",
      "it PRON PRP\n",
      "was AUX VBD\n",
      "excellent ADJ JJ\n",
      "  SPACE _SP\n",
      "the DET DT\n",
      "weather NOUN NN\n",
      "was AUX VBD\n",
      "perfect ADJ JJ\n",
      "which PRON WDT\n",
      "made VERB VBD\n",
      "sitting VERB VBG\n",
      "outside ADV RB\n",
      "overlooking VERB VBG\n",
      "their PRON PRP$\n",
      "grounds NOUN NNS\n",
      "an DET DT\n",
      "absolute ADJ JJ\n",
      "pleasure NOUN NN\n",
      "\n",
      " SPACE _SP\n",
      "our PRON PRP$\n",
      "waitress NOUN NN\n",
      "was AUX VBD\n",
      "excellent ADJ JJ\n",
      "and CCONJ CC\n",
      "our PRON PRP$\n",
      "food NOUN NN\n",
      "arrived VERB VBD\n",
      "quickly ADV RB\n",
      "on ADP IN\n",
      "the DET DT\n",
      "semibusy ADJ JJ\n",
      "saturday PROPN NNP\n",
      "morning NOUN NN\n",
      "  SPACE _SP\n",
      "it PRON PRP\n",
      "looked VERB VBD\n",
      "like SCONJ IN\n",
      "the DET DT\n",
      "place NOUN NN\n",
      "fills VERB VBZ\n",
      "up ADP RP\n",
      "pretty ADV RB\n",
      "quickly ADV RB\n",
      "so SCONJ IN\n",
      "the DET DT\n",
      "earlier ADV RBR\n",
      "you PRON PRP\n",
      "get VERB VBP\n",
      "here ADV RB\n",
      "the DET DT\n",
      "better ADJ JJR\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "do VERB VBP\n",
      "yourself PRON PRP\n",
      "a DET DT\n",
      "favor NOUN NN\n",
      "and CCONJ CC\n",
      "get VERB VB\n",
      "their PRON PRP$\n",
      "bloody ADJ JJ\n",
      "mary NOUN NN\n",
      "  SPACE _SP\n",
      "it PRON PRP\n",
      "was AUX VBD\n",
      "phenomenal ADJ JJ\n",
      "and CCONJ CC\n",
      "simply ADV RB\n",
      "the DET DT\n",
      "best ADJ JJS\n",
      "i PRON PRP\n",
      "ve AUX VBP\n",
      "ever ADV RB\n",
      "had VERB VBN\n",
      "\n",
      " SPACE _SP\n",
      "i PRON PRP\n",
      "m VERB VBP\n",
      "pretty ADV RB\n",
      "sure ADJ JJ\n",
      "they PRON PRP\n",
      "only ADV RB\n",
      "use VERB VBP\n",
      "ingredients NOUN NNS\n",
      "from ADP IN\n",
      "their PRON PRP$\n",
      "garden NOUN NN\n",
      "and CCONJ CC\n",
      "blend VERB VB\n",
      "them PRON PRP\n",
      "fresh ADJ JJ\n",
      "when SCONJ WRB\n",
      "you PRON PRP\n",
      "order VERB VBP\n",
      "it PRON PRP\n",
      "  SPACE _SP\n",
      "it PRON PRP\n",
      "was AUX VBD\n",
      "amazing ADJ JJ\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "while SCONJ IN\n",
      "everything PRON NN\n",
      "on ADP IN\n",
      "the DET DT\n",
      "menu NOUN NN\n",
      "looks VERB VBZ\n",
      "excellent ADJ JJ\n",
      "i PRON PRP\n",
      "had VERB VBD\n",
      "the DET DT\n",
      "white PROPN NNP\n",
      "truffle PROPN NNP\n",
      "scrambled VERB VBN\n",
      "eggs PROPN NNP\n",
      "vegetable NOUN NN\n",
      "skillet NOUN NN\n",
      "and CCONJ CC\n",
      "it PRON PRP\n",
      "was AUX VBD\n",
      "tasty ADJ JJ\n",
      "and CCONJ CC\n",
      "delicious ADJ JJ\n",
      "\n",
      " SPACE _SP\n",
      "it PRON PRP\n",
      "came VERB VBD\n",
      "with ADP IN\n",
      "2 NUM CD\n",
      "pieces NOUN NNS\n",
      "of ADP IN\n",
      "their PRON PRP$\n",
      "griddled VERB VBN\n",
      "bread NOUN NN\n",
      "with SCONJ IN\n",
      "was AUX VBD\n",
      "amazing ADJ JJ\n",
      "and CCONJ CC\n",
      "it PRON PRP\n",
      "absolutely ADV RB\n",
      "made VERB VBD\n",
      "the DET DT\n",
      "meal NOUN NN\n",
      "complete ADJ JJ\n",
      "\n",
      " SPACE _SP\n",
      "it PRON PRP\n",
      "was AUX VBD\n",
      "the DET DT\n",
      "best ADJ JJS\n",
      "toast NOUN NN\n",
      "i PRON PRP\n",
      "ve AUX VBP\n",
      "ever ADV RB\n",
      "had VERB VBN\n",
      "\n",
      "\n",
      " SPACE _SP\n",
      "anyway ADV RB\n",
      "i PRON PRP\n",
      "ca AUX MD\n",
      "nt PART RB\n",
      "wait VERB VB\n",
      "to PART TO\n",
      "go VERB VB\n",
      "back ADV RB\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_df:\n",
    "    print(doc.text, doc.pos_, doc.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "xpT1c8mOuw48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "xpT1c8mOuw48",
    "outputId": "510d1a67-9eaf-423c-cc7f-3c27ffeef668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[my wife, me, my birthday, breakfast, it, the weather, which, their grounds, an absolute pleasure, our waitress, our food, it, the place, you, yourself, a favor, their bloody mary, it, i, i, they, ingredients, their garden, them, you, it, it, everything, the menu, i, the white truffle scrambled eggs vegetable skillet, it, it, 2 pieces, their griddled bread, it, the meal, it, the best toast, i, i]\n"
     ]
    }
   ],
   "source": [
    "# spaCy also does some basic noun chunking\n",
    "print([chunk for chunk in doc_df.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04TKLmP9uwsr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "04TKLmP9uwsr",
    "outputId": "5eff5d63-8ec2-47e1-c552-67f3150c0fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob_df = TextBlob(train_text)\n",
    "type(blob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "QtspxsNd0aKQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QtspxsNd0aKQ",
    "outputId": "8b798e6f-c599-4d4d-a398-2122b7c6f774"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " ('took', 'VBD'),\n",
       " ('me', 'PRP'),\n",
       " ('here', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('birthday', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('breakfast', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('excellent', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('weather', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('perfect', 'JJ'),\n",
       " ('which', 'WDT'),\n",
       " ('made', 'VBD'),\n",
       " ('sitting', 'VBG'),\n",
       " ('outside', 'IN'),\n",
       " ('overlooking', 'VBG'),\n",
       " ('their', 'PRP$'),\n",
       " ('grounds', 'NNS'),\n",
       " ('an', 'DT'),\n",
       " ('absolute', 'JJ'),\n",
       " ('pleasure', 'NN'),\n",
       " ('our', 'PRP$'),\n",
       " ('waitress', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('excellent', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('our', 'PRP$'),\n",
       " ('food', 'NN'),\n",
       " ('arrived', 'VBD'),\n",
       " ('quickly', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('semibusy', 'JJ'),\n",
       " ('saturday', 'NN'),\n",
       " ('morning', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('looked', 'VBD'),\n",
       " ('like', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('place', 'NN'),\n",
       " ('fills', 'VBZ'),\n",
       " ('up', 'RP'),\n",
       " ('pretty', 'RB'),\n",
       " ('quickly', 'RB'),\n",
       " ('so', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('earlier', 'JJR'),\n",
       " ('you', 'PRP'),\n",
       " ('get', 'VBP'),\n",
       " ('here', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('better', 'JJR'),\n",
       " ('do', 'VB'),\n",
       " ('yourself', 'PRP'),\n",
       " ('a', 'DT'),\n",
       " ('favor', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('get', 'VB'),\n",
       " ('their', 'PRP$'),\n",
       " ('bloody', 'NN'),\n",
       " ('mary', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('phenomenal', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('simply', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('ive', 'JJ'),\n",
       " ('ever', 'RB'),\n",
       " ('had', 'VBD'),\n",
       " ('im', 'VBN'),\n",
       " ('pretty', 'RB'),\n",
       " ('sure', 'JJ'),\n",
       " ('they', 'PRP'),\n",
       " ('only', 'RB'),\n",
       " ('use', 'VBP'),\n",
       " ('ingredients', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('garden', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('blend', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('fresh', 'JJ'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('order', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('amazing', 'VBG'),\n",
       " ('while', 'IN'),\n",
       " ('everything', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('menu', 'NN'),\n",
       " ('looks', 'VBZ'),\n",
       " ('excellent', 'JJ'),\n",
       " ('i', 'NN'),\n",
       " ('had', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('white', 'JJ'),\n",
       " ('truffle', 'NN'),\n",
       " ('scrambled', 'VBD'),\n",
       " ('eggs', 'NNS'),\n",
       " ('vegetable', 'JJ'),\n",
       " ('skillet', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('tasty', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('delicious', 'JJ'),\n",
       " ('it', 'PRP'),\n",
       " ('came', 'VBD'),\n",
       " ('with', 'IN'),\n",
       " ('2', 'CD'),\n",
       " ('pieces', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('griddled', 'VBN'),\n",
       " ('bread', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('was', 'VBD'),\n",
       " ('amazing', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('absolutely', 'RB'),\n",
       " ('made', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('meal', 'NN'),\n",
       " ('complete', 'JJ'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('toast', 'NN'),\n",
       " ('ive', 'JJ'),\n",
       " ('ever', 'RB'),\n",
       " ('had', 'VBD'),\n",
       " ('anyway', 'RB'),\n",
       " ('i', 'JJ'),\n",
       " ('cant', 'VBP'),\n",
       " ('wait', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('back', 'RB')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cpxSbbEq0aHZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "cpxSbbEq0aHZ",
    "outputId": "4a590554-f426-4284-df0a-40dd293b8239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolute pleasure', 'semibusy saturday morning', 'place fills', 'bloody mary', 'excellent i', 'white truffle', 'vegetable skillet', 'i cant']\n"
     ]
    }
   ],
   "source": [
    "# textblob can do some basic noun chunking\n",
    "print([np for np in blob_df.noun_phrases])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0dad7",
   "metadata": {
    "id": "2eb0dad7"
   },
   "source": [
    "## **Question 3**. Comparing the outputs of spacy and textblob chunking in tast 3, which one would you like to use in your application? Explain it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db2d58",
   "metadata": {
    "id": "26db2d58"
   },
   "source": [
    "**Answer to Q3**:\n",
    "Both spaCy and TextBlob tokenize the phrases 'an absolute pleasure', 'semibusy saturday morning', 'place fills', 'bloody mary', and 'excellent i' in the same way.The spaCy tokenization includes additional details such as 'scrambled eggs' in the 'white truffle scrambled eggs vegetable skillet', '2 pieces' (presumably referring to the griddled bread), 'the meal', and 'the best toast'.\n",
    "TextBlob's tokenization separates 'white truffle' and 'vegetable skillet' into two separate tokens, while spaCy treats it as a single token.\n",
    "TextBlob tokenizes 'i cant' as two separate tokens, whereas spaCy treats it as a single token 'i' with the contraction 'cant'.These differences in tokenization can occur due to variations in the underlying algorithms and rule-based approaches used by spaCy and TextBlob. It's important to note that tokenization results can vary depending on the specific library, configuration, and language model used.Finally, if the application requires highly accurate tokenization, complex linguistic analysis, multi-language support, or additional NLP functionalities, spaCy would be the recommended choice. On the other hand, if simplicity, ease of use, and integration with NLTK are more important, TextBlob may be a suitable option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4e604",
   "metadata": {
    "id": "aed4e604"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f1d8aa",
   "metadata": {
    "id": "03f1d8aa"
   },
   "source": [
    "## Question 4. Whats the disadvantage in bag of words  . Please explain in your own words with an example .\n",
    "\n",
    "## Write code for the example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258397a",
   "metadata": {
    "id": "2258397a"
   },
   "source": [
    "### Answer to Q4:\n",
    "The main disadvantage in bag of words ,it doesn't maintain the order and structure of the words in a sentence. It treats each word as one feature , and it contains frequency of words in particular sentence. It doesn't maintain the semantic meaning of words while applying to text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "HWAZ19fgmTF4",
   "metadata": {
    "id": "HWAZ19fgmTF4"
   },
   "outputs": [],
   "source": [
    "text_doc=[\n",
    "\"Politics is the practice and study of influencing decisions that apply to members of a group or society, and it involves the exercise of power and authority to achieve collective goals.\",\n",
    "\"Political systems can vary from democracies to autocracies, and political ideologies shape the policies and principles guiding governance.\",\n",
    "\"Elections, political campaigns, and public opinion play crucial roles in determining the composition of governments and shaping policy outcomes.\",\n",
    "\"Political discourse encompasses debates on issues such as social justice, economic inequality, human rights, environmental sustainability, and foreign relations.\",\n",
    "\"Political leaders and policymakers formulate and implement laws, regulations, and public policies that have a direct impact on citizens' lives and shape the direction of a nation or region.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d3b1a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05d3b1a6",
    "outputId": "eb4d6b63-0d5d-4fa5-c3a6-f9dbc8f46292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 2, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Defining object for count vectorizer\n",
    "bagofwords= CountVectorizer()\n",
    "\n",
    "# Applying bagofwords to text_doc\n",
    "bagofwordsarray = bagofwords.fit_transform(text_doc)\n",
    "# array representation\n",
    "bagofwordsarray.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "zqRDH9zuhJP6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqRDH9zuhJP6",
    "outputId": "5215ca5b-136e-4f77-beb5-8d38d56a79e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['achieve', 'and', 'apply', 'as', 'authority', 'autocracies',\n",
       "       'campaigns', 'can', 'citizens', 'collective', 'composition',\n",
       "       'crucial', 'debates', 'decisions', 'democracies', 'determining',\n",
       "       'direct', 'direction', 'discourse', 'economic', 'elections',\n",
       "       'encompasses', 'environmental', 'exercise', 'foreign', 'formulate',\n",
       "       'from', 'goals', 'governance', 'governments', 'group', 'guiding',\n",
       "       'have', 'human', 'ideologies', 'impact', 'implement', 'in',\n",
       "       'inequality', 'influencing', 'involves', 'is', 'issues', 'it',\n",
       "       'justice', 'laws', 'leaders', 'lives', 'members', 'nation', 'of',\n",
       "       'on', 'opinion', 'or', 'outcomes', 'play', 'policies', 'policy',\n",
       "       'policymakers', 'political', 'politics', 'power', 'practice',\n",
       "       'principles', 'public', 'region', 'regulations', 'relations',\n",
       "       'rights', 'roles', 'shape', 'shaping', 'social', 'society',\n",
       "       'study', 'such', 'sustainability', 'systems', 'that', 'the', 'to',\n",
       "       'vary'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namesfeature = bagofwords.get_feature_names_out()\n",
    "namesfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Asub2L_hd06",
   "metadata": {
    "id": "7Asub2L_hd06"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
